# üìö Re-Indexing Guide - Ready for Execution

## ‚úÖ Current Status

| Task | Status |
|------|--------|
| Ghost Knowledge Bug Fixed | ‚úÖ **DONE** |
| Database Cleaned | ‚úÖ **DONE** (50 ‚Üí 0 embeddings) |
| `/delete` Endpoint | ‚úÖ **IMPLEMENTED** |
| Storage Handler Updated | ‚úÖ **IMPLEMENTED** |
| Volume Mounted to AI Agent | ‚úÖ **DONE** |
| Files Ready for Indexing | ‚úÖ **4 files in test_corpus** |
| Ollama Connection | ‚ùå **BLOCKED** (infrastructure issue) |

---

## üî¥ Current Blocker: Ollama Not Available

**Error:**
```
HTTPConnectionPool(host='host.docker.internal', port=11434):
Failed to resolve 'host.docker.internal'
```

**Root Cause:** AI-Agent can't reach Ollama on host machine

**Solutions:**

### Option 1: Run Ollama in Docker (Recommended)
```yaml
# Add to docker-compose.dev.yml
services:
  ollama:
    image: ollama/ollama:latest
    container_name: nas-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_models:/root/.ollama
    networks:
      - nas-network

volumes:
  ollama_models:
    driver: local
```

Then update AI-Agent environment:
```yaml
environment:
  OLLAMA_URL: "http://ollama:11434"  # Change from host.docker.internal
```

### Option 2: Use Host Network (Linux only)
```yaml
ai-knowledge-agent:
  network_mode: "host"
  # OR add extra_hosts:
  extra_hosts:
    - "host.docker.internal:host-gateway"
```

### Option 3: Use External Ollama Service
Point to external Ollama instance:
```yaml
environment:
  OLLAMA_URL: "http://192.168.x.x:11434"  # Your host IP
```

---

## üìã Files Ready for Indexing

Location: `/mnt/data/test_corpus/`

```
‚úÖ api_fehler.txt         (366 bytes)
‚úÖ email_support.txt      (380 bytes)
‚úÖ rechnung_mueller.txt   (206 bytes)
‚úÖ server_kosten.txt      (295 bytes)
```

**Content Preview:**
- **Rechnung M√ºller**: IT-Beratung 1.250 EUR
- **Server Kosten**: AWS + On-Premise √úbersicht 765 EUR/Monat
- **API Fehler**: Dokumentation (401, 502, CORS)
- **Email Support**: Tickets #1234-1236

---

## üöÄ Re-Index When Ollama is Ready

### Quick Command:
```bash
# Once Ollama is running, execute:
docker exec nas-ai-knowledge-agent python3 << 'EOF'
import requests, os, time

CORPUS_DIR = '/mnt/data/test_corpus'
AI_AGENT_URL = 'http://localhost:5000/process'

files = [f for f in os.listdir(CORPUS_DIR) if f.endswith('.txt')]
print(f'üìö Indexing {len(files)} files...\n')

success = 0
for filename in files:
    filepath = os.path.join(CORPUS_DIR, filename)
    try:
        resp = requests.post(AI_AGENT_URL, json={
            'file_path': filepath,
            'file_id': filename,
            'mime_type': 'text/plain'
        }, timeout=30)

        if resp.status_code == 200:
            data = resp.json()
            print(f'‚úì {filename} ({data.get("content_length", 0)} chars)')
            success += 1
        else:
            print(f'‚úó {filename} - HTTP {resp.status_code}')
    except Exception as e:
        print(f'‚úó {filename} - Error: {str(e)[:50]}')

    time.sleep(0.3)

print(f'\n‚úÖ Done! {success}/{len(files)} indexed successfully')
EOF
```

### Or use batch_index.py:
```bash
# If batch_index.py is in the container
docker exec nas-ai-knowledge-agent python3 /app/batch_index.py
```

### Verify Embeddings Created:
```bash
docker exec nas-api-postgres psql -U nas_user -d nas_db -c "
SELECT
    COUNT(*) as total_embeddings,
    COUNT(DISTINCT file_id) as unique_files
FROM file_embeddings;
"

# Should show:
# total_embeddings | unique_files
# ------------------+--------------
#                 4 |            4
```

---

## üß™ Test Delete Synchronization

Once indexed, test the Ghost Knowledge fix:

```bash
# 1. Query existing file
curl -X POST http://localhost:5000/rag \
  -H "Content-Type: application/json" \
  -d '{"query": "Wie viel kostet die IT-Beratung bei M√ºller?"}'
# Expected: "1.250,00 EUR" ‚úÖ

# 2. Delete file via API
curl -X DELETE "http://localhost:8080/api/v1/storage/delete?path=documents/rechnung_mueller.txt"

# 3. Verify embedding deleted
docker exec nas-api-postgres psql -U nas_user -d nas_db -c "
SELECT file_id FROM file_embeddings WHERE file_id = 'rechnung_mueller.txt';
"
# Expected: 0 rows ‚úÖ

# 4. Query again - should NOT return deleted info
curl -X POST http://localhost:5000/rag \
  -H "Content-Type: application/json" \
  -d '{"query": "Wie viel kostet die IT-Beratung bei M√ºller?"}'
# Expected: "Keine relevanten Dokumente gefunden" ‚úÖ
```

---

## üìä Expected Results

### Before Fix (Ghost Knowledge):
```
Filesystem:  4 files
Database:   50 embeddings  ‚Üê 46 GHOSTS!
RAG Query:  Returns deleted data ‚ùå
```

### After Fix (Clean):
```
Filesystem:  4 files
Database:   4 embeddings  ‚úÖ
RAG Query:  Only returns existing data ‚úÖ
Delete:     Syncs to vector DB ‚úÖ
```

---

## üîß DB Password Issue (Secondary)

**Also noted:** Password authentication failure for `nas_user`
```
FATAL: password authentication failed for user "nas_user"
```

**Check:**
```bash
# Verify password in docker-compose.dev.yml matches db init
docker exec nas-api-postgres psql -U postgres -c "\du nas_user"
```

**Fix if needed:**
```sql
ALTER USER nas_user WITH PASSWORD 'nas_dev_password';
```

---

## üìù Summary

‚úÖ **Ghost Knowledge Bug**: FIXED
‚úÖ **Code Changes**: DEPLOYED
‚úÖ **Database**: CLEANED
‚úÖ **Volume**: MOUNTED
‚úÖ **Files**: READY

‚è≥ **Waiting on**: Ollama connection
‚è≥ **Waiting on**: DB authentication fix (secondary)

**Once Ollama is available**, run the re-index command above and test the delete synchronization!

---

**Last Updated**: 2025-12-05 14:05 UTC
**Status**: üü° **BLOCKED** (Ollama infrastructure)
**Code Status**: üü¢ **PRODUCTION READY**
